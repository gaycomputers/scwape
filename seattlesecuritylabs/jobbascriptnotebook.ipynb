{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING! \n",
    "### This notebook will get you banned by Google after some usage. This is because (despite 90% of my results being scraped off of public government websites) Google cannot differentiate between a thorough job search and a competitor, and once this script uses your built database to make calls they will disable your API key, usually with a temporary ban first.\n",
    "This notebook got me 4 interviews and they were all for web hacking jobs I was not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import typer\n",
    "import googlemaps\n",
    "import time\n",
    "import pandas as pd\n",
    "import inspect\n",
    "#import sys\n",
    "import requests\n",
    "import scrapy\n",
    "from scrapy_splash import SplashRequest\n",
    "import scrapy_splash\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objinfo(obj):\n",
    "    for i in dir(obj):\n",
    "       print(i, getattr(obj, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def defaults(defawlt):\n",
    "    #defult = input(\"Please enter a value for {}: \".format(defawlt))\n",
    "    #try:\n",
    "    #    defult = int(defult)\n",
    "    #finally:\n",
    "    #    return defult\n",
    "    return input(\"Please enter a value for {}: \".format(defawlt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def locations(df, key):\n",
    "    (sites, failures) = list_websites(df, key)\n",
    "    #print(sites)\n",
    "    #print(failures)\n",
    "    final_locations = []\n",
    "    for i in sites:\n",
    "        if i[0] != None:\n",
    "            uri = find_landing(i[0])\n",
    "            print(\"At {}, we found {}\".format(df['name'][i[2]],\"{}{}\".format(uri[0],uri[1])))\n",
    "            final_locations.append(uri[1])\n",
    "    return final_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rate_limiting(rate):\n",
    "    print(\"Got rate limited, chillin for a bit\")\n",
    "    time.sleep(1+rate)\n",
    "    print(\"Ok back to work\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_landing(site): #currently fails with some dynamic sites\n",
    "    landingsfile = open('joblandings.txt', 'r')\n",
    "    landingslist = landingsfile.read().split('\\n')\n",
    "    for i in landingslist:\n",
    "        #print(i, site)\n",
    "        try:\n",
    "            #print(\"trying {}\".format(\"{}{}\".format(site, i)))\n",
    "            response = requests.head(\"{}{}\".format(site, i))\n",
    "            #print(\"got {}\".format(response.status_code))\n",
    "            while response.status_code == 429:\n",
    "                i = 0\n",
    "                rate_limiting(i)\n",
    "                response = requests.head(\"{}{}\".format(site, i))\n",
    "                i += 2\n",
    "                if i >= 20:\n",
    "                    break\n",
    "            if response.status_code >= 300 and response.status_code < 400:\n",
    "                response = requests.head(re.sub(r\"http:\\/\\/\",\"https://\",\"{}{}\".format(site, i)))\n",
    "                \n",
    "        except requests.ConnectionError as e:\n",
    "            #print(\"Connection error: {}\".format(e))\n",
    "            pass\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return (\"job landing: \",\"{}{}\".format(site, i))\n",
    "    return (\"no job landing, just \",\"{}\".format(site))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_websites(df, key):\n",
    "    sites = []\n",
    "    failures = []\n",
    "    for i in range(0, len(df)):\n",
    "            print(i)\n",
    "            sites.append((json.loads()[\"result\"].get(\"website\"), df['place_id'][i], i))\n",
    "            if sites[-1] == None:\n",
    "                print(\"Location {} does not have a listed website, adding to failures.\".format(df['name'][i]))\n",
    "                failures.append(df['place_id'][i])\n",
    "                sites.pop()\n",
    "    return (sites, failures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crawl(url):\n",
    "    #res = yield requests.get(url)\n",
    "    #print(res)\n",
    "    print(\"test\")\n",
    "    yield SplashRequest(url, self.parse_result,\n",
    "    args={\n",
    "        # optional; parameters passed to Splash HTTP API\n",
    "        'wait': 0.5,\n",
    "\n",
    "        # 'url' is prefilled from request url\n",
    "        # 'http_method' is set to 'POST' for POST requests\n",
    "        # 'body' is set to request body for POST requests\n",
    "    },\n",
    "    endpoint='render.json', # optional; default is render.html\n",
    "    splash_url='<url>',     # optional; overrides SPLASH_URL\n",
    "    slot_policy=scrapy_splash.SlotPolicy.PER_DOMAIN,  # optional\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_website(key, placeid):\n",
    "    #currently requests too many fields that are not used\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/details/json?place_id={}&fields=name%2Crating%2Cwebsite&key={}\".format(placeid, key)\n",
    "    payload={}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def places_crawl(key, geo, search_string, radius):\n",
    "    radius = int(radius)\n",
    "    (lat, lng) = map(geo[0]['geometry']['location'].get, ('lat', 'lng'))\n",
    "    theplaces = []\n",
    "    for i in range(-radius, radius):\n",
    "        for j in range(-radius, radius):\n",
    "            t = lat + i*(1/69)\n",
    "            g = lng + j*(1/69)\n",
    "            place = places(key, (t,g), search_string, 1.41421356236)\n",
    "            if place.empty:\n",
    "                pass\n",
    "            else: \n",
    "                #pd.concat([theplaces, place], axis=0)\n",
    "                theplaces.append(place)\n",
    "                #print(place)\n",
    "                print(theplaces)\n",
    "    return theplaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def places(key, geo, search_string, radius):\n",
    "    (lat, lng) = geo\n",
    "    gmaps = googlemaps.Client(key)\n",
    "    response = gmaps.places_nearby(\n",
    "            location=(lat, lng),\n",
    "            keyword=search_string,\n",
    "            radius=int(radius) * 1_609.344\n",
    "    )\n",
    "    places = []\n",
    "    places.extend(response.get('results'))\n",
    "    token = response.get('next_page_token')\n",
    "    while token:\n",
    "        time.sleep(2)\n",
    "        response = gmaps.places_nearby(\n",
    "            location=(lat, lng),\n",
    "            keyword=search_string,\n",
    "            radius=int(radius) * 1_609.344,\n",
    "            page_token=token\n",
    "        )\n",
    "        places.extend(response.get('results'))\n",
    "        token = response.get('next_page_token')\n",
    "    df = pd.DataFrame(places)\n",
    "    #df['url'] = 'https://www.google.com/maps/place/?q=place_id:' + df['place_id']\n",
    "    #df.to_excel('{0}.xlsx'.format(search_string), index=False)\n",
    "    #return pd.read_excel('{0}.xlsx'.format(search_string))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(startpoint: str=\"\", radius: int=0, search_string: str=\"\", key: str=\"\"):\n",
    "    args = vars()\n",
    "    typer.echo(f\"Hello! Would you like a job?\")\n",
    "\n",
    "    argspec=inspect.getargvalues(inspect.currentframe())\n",
    "    for arg in argspec.args:\n",
    "        if args[arg] == \"\" or args[arg] == 0:\n",
    "            args[arg] = defaults(arg)\n",
    "    gmaps = googlemaps.Client(args[\"key\"])\n",
    "    #geo = gmaps.geocode(address=args[\"startpoint\"])\n",
    "    #df2 = places_crawl(args[\"key\"], geo, args[\"search_string\"], args[\"radius\"])\n",
    "    \n",
    "    #print(df2)\n",
    "    #df = pd.concat(df2, axis=0, ignore_index=True)\n",
    "    df = pd.read_excel('no.xlsx')\n",
    "    df = df.drop_duplicates(subset=['place_id'])\n",
    "    df['url'] = 'https://www.google.com/maps/place/?q=place_id:' + df['place_id']\n",
    "    df.to_excel('{0}.xlsx'.format(args[\"search_string\"]), index=False)\n",
    "    print(df)\n",
    "    #print(df2)\n",
    "    #df = pd.read_excel('tmp.xlsx')\n",
    "    #final_locations = []\n",
    "    #for i in df2:\n",
    "    #    final_locations += locations(i, args[\"key\"])\n",
    "    final_locations = locations(df, args[\"key\"])\n",
    "    print(\"\\n\\nHere is your to-dos: \")\n",
    "    for i in [*set(final_locations)]:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    typer.run(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
